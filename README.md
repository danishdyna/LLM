# Tutorial
## Open Source LLMs On-Prem
* [Ollama Application Platform](https://github.com/danishdyna/LLM/blob/main/Ollama-Run.md)
* [On-Prem HW - $1000 PC and HPC Cluster](https://github.com/danishdyna/LLM/blob/main/Ollama-Run.md)
* [On-Prem HCP Cluster](https://github.com/danishdyna/LLM/blob/main/Ollama-Run.md)
* [Model Create](https://github.com/danishdyna/LLM/blob/main/Ollama-Create.md)
* [Model Import](https://github.com/danishdyna/LLM/blob/main/Ollama-Import.md)
* [API REST](https://github.com/danishdyna/LLM/blob/main/Ollama-REST.md)
* [API Python](https://github.com/danishdyna/LLM/blob/main/Ollama-Python.md)
* [Ollama Function Calling](https://github.com/danishdyna/LLM/blob/main/Ollama-Function.md)
* [Ollama RAG](https://github.com/danishdyna/LLM/blob/main/Ollama-RAG.md)
* [Ollama Agents](https://github.com/danishdyna/LLM/blob/main/Ollama-Agents.md)
* [Nvidia Launchpad](https://github.com/danishdyna/LLM/blob/main/Nvidia-Launchpad.md)
* [Nvidia NIM](https://github.com/danishdyna/LLM/blob/main/Nvidia-NIM.md)

### New Topics
Benchmark on own data: https://www.promptfoo.dev/docs/guides/phi-vs-llama/

<sub><sub>
[#Ollama](https://github.com/ollama)
[#Mark-Down](https://daringfireball.net/projects/markdown)
