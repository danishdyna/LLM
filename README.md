# Tutorial
## Open Source LLMs running Ollama
* [Ollama Application Platform](https://github.com/danishdyna/LLM/blob/main/Ollama-Run.md)
* [LLM on $1000 PC](https://github.com/danishdyna/LLM/blob/main/Ollama-Run.md)
* [LLM on HCP Cluster](https://github.com/danishdyna/LLM/blob/main/Ollama-Run.md)
* [Ollama Create Model](https://github.com/danishdyna/LLM/blob/main/Ollama-Create.md)
* [Ollama Import Model](https://github.com/danishdyna/LLM/blob/main/Ollama-Import.md)
* [Ollama REST API](https://github.com/danishdyna/LLM/blob/main/Ollama-REST.md)
* [Ollama Python API](https://github.com/danishdyna/LLM/blob/main/Ollama-Python.md)
* [Ollama Function Calling](https://github.com/danishdyna/LLM/blob/main/Ollama-Function.md)
* [Ollama RAG](https://github.com/danishdyna/LLM/blob/main/Ollama-RAG.md)
* [Ollama Agents](https://github.com/danishdyna/LLM/blob/main/Ollama-Agents.md)
* [Nvidia Launchpad](https://github.com/danishdyna/LLM/blob/main/Nvidia-Launchpad.md)
* [Nvidia NIM](https://github.com/danishdyna/LLM/blob/main/Nvidia-NIM.md)

### New Topics
Benchmark on own data: https://www.promptfoo.dev/docs/guides/phi-vs-llama/

<sub><sub>
[#Ollama](https://github.com/ollama)
[#Mark-Down](https://daringfireball.net/projects/markdown)
